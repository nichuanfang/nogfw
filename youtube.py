#!/usr/local/bin/python
# coding=utf-8
from time import sleep
import cv2
import requests
import logging
import io
from urllib import request, parse
import sys
import subprocess
from datetime import datetime
import os
import base64
import json
import yaml
import copy
import re
import qrcode
from qrcode import constants
# å›¾åƒè¯†åˆ«
import easyocr

data = ['ğŸ”° èŠ‚ç‚¹é€‰æ‹©','â™»ï¸ è‡ªåŠ¨é€‰æ‹©','ğŸ¯ å…¨çƒç›´è¿','ğŸ‡ºğŸ‡² ç¾å›½-4.03MB/s(Youtube:ä¸è‰¯æ—)']
data[-1] = '[1] '+data[-1].replace('(Youtube:ä¸è‰¯æ—)','')

# windowsä¸‹éœ€è¦å…ˆä¸‹è½½æ¨¡å‹æ–‡ä»¶  https://blog.csdn.net/Loliykon/article/details/114334699
reader = easyocr.Reader(['ch_sim','en'],model_storage_directory='ocr_models')

LOG_FORMAT = "%(asctime)s - %(levelname)s - %(message)s"
DATE_FORMAT = "%m/%d/%Y %H:%M:%S %p"
logging.basicConfig(level=logging.INFO, format=LOG_FORMAT, datefmt=DATE_FORMAT)

def qr_recognize(file_path:str):
    qrcode_filename = file_path
    qrcode_image = cv2.imread(qrcode_filename)
    qrCodeDetector = cv2.QRCodeDetector()
    data, bbox, straight_qrcode = qrCodeDetector.detectAndDecode(qrcode_image)
    return data

sys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding='utf-8')
raw_list = []
logging.basicConfig(level=logging.INFO)
def craw(number:int,video_id:str,sleeptime:int):
    all_nodes = []
    logging.info(f'===========================================================================å¼€å§‹è·å–èŠ‚ç‚¹ä¿¡æ¯...')
    count = 1
    # é»˜è®¤130
    for craw_index in range(number):
        logging.info(f'=====================================å¼€å§‹ç¬¬{craw_index+1}/{number}è½®æŠ“å–======================================================')
        # éš”ä¸€æ®µæ—¶é—´è·å–äºŒç»´ç 
        subprocess.call(f'ffmpeg -y -i "$(yt-dlp -g {video_id} | head -n 1)" -vframes 1 dist/last.jpg',shell=True)
        while True:
            if not os.path.exists('dist/last.jpg'):
                logging.info(f'==========================================================ç­‰å¾…æˆªå›¾ç”Ÿæˆ...======================================================')
                sleep(1)
            else:
                break
        try:
            logging.info(f'====================================={datetime.now().strftime("%Y-%m-%d %H:%M:%S")}--èŠ‚ç‚¹ä¿¡æ¯======================================================')
            # å¤„ç†ç”Ÿæˆçš„äºŒç»´ç  ç”ŸæˆèŠ‚ç‚¹ä¿¡æ¯
            data:str = qr_recognize(f'dist/last.jpg')
            raw_list.append(data)
            logging.info(f'===============================================================================raw_data: {data}')
            ocr_result = reader.readtext('dist/last.jpg')
            # additional handling to ocr result... 
            logging.info(f'===============================================================================OCR: {ocr_result}')
        except Exception as err:
            data = ''
            all_nodes = []
            logging.error(f'==============================={err}==============================================')
        sub_res = requests.get(f'https://sub.xeton.dev/sub?target=quanx&url={parse.quote(data)}&insert=false')
        sub_res_list: list[str] = sub_res.text.split('\n')
        for index,subitem in enumerate(sub_res_list):
            try:
                if subitem == '[server_local]' and sub_res_list[index+1] not in ['','[filter_local]']:
                    # æœ‰æ•ˆqxè®¢é˜…èŠ‚ç‚¹
                    # æ·»åŠ åˆ°ç›®æ ‡èŠ‚ç‚¹ä¸­
                    node = sub_res_list[index+1]
                    new_node = None
                    # æ›´æ”¹tag
                    match = re.search(r'tag.+$',node)
                    if match is not None:
                        tag = match.group()
                        new_tag = 'tag='+f'[{count}] '+tag.replace('(Youtube:ä¸è‰¯æ—)','').split('=')[1]
                        new_node = re.sub(r'tag.+$',new_tag,node)
                    if new_node == None:
                        continue
                    all_nodes.append(new_node)
                    count+=1
                    # å»é‡list(set(all_nodes))
                    all_nodes = sorted(set(all_nodes),key=all_nodes.index)
                    logging.info(f'==============================================================================å½“å‰èŠ‚ç‚¹æ± æœ‰: {len(all_nodes)}ä¸ªèŠ‚ç‚¹')
                    logging.info(f'')
                    logging.info(f'')
                    logging.info(f'')
                    logging.info(f'')
            except:
                continue
        if craw_index != number-1:
            sleep(sleeptime)
    return all_nodes


def generate_clash_config(raw_list:list,final_dict:dict): # type: ignore
    count = 1
    for index,raw in enumerate(raw_list):
        logging.info(f'handle raw:{raw}======================================')
        # sub_res = request.urlopen(f'https://sub.xeton.dev/sub?target=clash&url={parse.quote(raw)}&insert=false')
        sub_res = requests.get(f'https://sub.xeton.dev/sub?target=clash&url={parse.quote(raw)}&insert=false')
        # logging.info(f'è®¢é˜…è½¬æ¢åçš„å“åº”:çŠ¶æ€ç :{sub_res.status_code}  ok:{sub_res.ok}=====================================================')
        # logging.info(f'clash dict:{sub_res.text}======================================')
        if not sub_res.ok:
            continue
        try:
            data_dict:dict = yaml.load(sub_res.text, Loader=yaml.FullLoader)
            #logging.info(f'clash dict:{data_dict}======================================')
            if not final_dict:
                final_dict:dict = copy.deepcopy(data_dict)
                final_dict['socks-port'] = 10808 # type: ignore
                final_dict['port'] = 10809 # type: ignore
            #   #è‡ªåŠ¨é€‰æ‹© å¤šä¹…æ£€æµ‹ä¸€æ¬¡é€Ÿåº¦ è‡ªåŠ¨åˆ‡æ¢ å•ä½s(ç§’)
                final_dict['proxy-groups'][1]['interval'] = 1800 # type: ignore
                # å‰”é™¤ä½å»¶è¿ŸèŠ‚ç‚¹
                if not bool(re.search(r'é¦™æ¸¯|Hong Kong|HK|hk|æ–°åŠ å¡|Singapore|SG|sg|å°æ¹¾|Taiwan|TW|tw|å°åŒ—|æ—¥æœ¬|Japan|JP|jp|éŸ©å›½|Korea|KR|kr',final_dict['proxy-groups'][1]['proxies'][0])):
                    final_dict['proxy-groups'][1]['proxies'] = []
                else:
                    final_dict['proxy-groups'][1]['proxies'][-1] = f'[{count}] '+final_dict['proxy-groups'][1]['proxies'][-1].replace('(Youtube:ä¸è‰¯æ—)','')
                proxy:dict= copy.deepcopy(data_dict['proxies'][0])
                final_dict['proxies'][0]['name'] = f'[{count}] ' + proxy['name'].replace('(Youtube:ä¸è‰¯æ—)','')
                final_dict['proxy-groups'][2]['proxies'][-1] = f'[{count}] '+final_dict['proxy-groups'][2]['proxies'][-1].replace('(Youtube:ä¸è‰¯æ—)','')
                final_dict['proxy-groups'][4]['proxies'][-1] = f'[{count}] '+final_dict['proxy-groups'][4]['proxies'][-1].replace('(Youtube:ä¸è‰¯æ—)','')
                final_dict['proxy-groups'][5]['proxies'][-1] = f'[{count}] '+final_dict['proxy-groups'][5]['proxies'][-1].replace('(Youtube:ä¸è‰¯æ—)','')
                final_dict['proxy-groups'][6]['proxies'][-1] = f'[{count}] '+final_dict['proxy-groups'][6]['proxies'][-1].replace('(Youtube:ä¸è‰¯æ—)','')
                final_dict['proxy-groups'][9]['proxies'][-1] = f'[{count}] '+final_dict['proxy-groups'][9]['proxies'][-1].replace('(Youtube:ä¸è‰¯æ—)','')
                count+=1
            else:
                # æ·»åŠ èŠ‚ç‚¹
                proxy:dict= copy.deepcopy(data_dict['proxies'][0])

                proxy['name'] = f'[{count}] ' + proxy['name'].replace('(Youtube:ä¸è‰¯æ—)','')

                final_dict['proxies'].append(proxy)

                # åˆ†ç»„é…ç½®

                # èŠ‚ç‚¹é€‰æ‹©
                final_dict['proxy-groups'][0]['proxies'].append(proxy['name']) # type: ignore
                # è‡ªåŠ¨é€‰æ‹©

                # æ­£åˆ™åŒ¹é… æ’é™¤å»¶è¿Ÿä½çš„èŠ‚ç‚¹
                if bool(re.search(r'é¦™æ¸¯|Hong Kong|HK|hk|æ–°åŠ å¡|Singapore|SG|sg|å°æ¹¾|Taiwan|TW|tw|å°åŒ—|æ—¥æœ¬|Japan|JP|jp|éŸ©å›½|Korea|KR|kr',proxy['name'])):
                    final_dict['proxy-groups'][1]['proxies'].append(proxy['name']) # type: ignore
                # å›½å¤–åª’ä½“
                final_dict['proxy-groups'][2]['proxies'].append(proxy['name']) # type: ignore
                # å¾®è½¯æœåŠ¡
                final_dict['proxy-groups'][4]['proxies'].append(proxy['name']) # type: ignore
                # ç”µæŠ¥ä¿¡æ¯
                final_dict['proxy-groups'][5]['proxies'].append(proxy['name']) # type: ignore
                # è‹¹æœæœåŠ¡
                final_dict['proxy-groups'][6]['proxies'].append(proxy['name']) # type: ignore
                # æ¼ç½‘ä¹‹é±¼
                final_dict['proxy-groups'][9]['proxies'].append(proxy['name']) # type: ignore
                count+=1
        except Exception as e:
            logging.error(f'=========================================raw:{raw}è½¬æ¢ä¸ºclashé…ç½®æ–‡ä»¶å¤±è´¥!: {e}')
    return final_dict


if __name__ == '__main__':
    # sys.argv[1]): CRAW_NUMBER æŠ“å–æ¬¡æ•°
    all_nodes = craw(int(sys.argv[1]),'qmRkvKo-KbQ',10)
    # ç”Ÿæˆqxä¸“ç”¨è®¢é˜…
    open('dist/qx-sub','w+').write('\n'.join(all_nodes))

    # ç”Ÿæˆclashé…ç½®æ–‡ä»¶
    logging.info(f'=========================================================================ç”Ÿæˆclashé…ç½®æ–‡ä»¶...')

    # raw_list = ['vmess://eyJ2IjoiMiIsInBzIjoi576O5Zu9LTUuNjNNQi9zKFlvdXR1YmU65LiN6Imv5p6XKSIsImFkZCI6IjIzLjIyNC4xMTAuMTg0IiwicG9ydCI6IjQ0MyIsInR5cGUiOiJub25lIiwiaWQiOiI0MTgwNDhhZi1hMjkzLTRiOTktOWIwYy05OGNhMzU4MGRkMjQiLCJhaWQiOiI2NCIsIm5ldCI6IndzIiwicGF0aCI6Ii9wYXRoLzA4MDcxMjM0MjMxMCIsImhvc3QiOiIiLCJ0bHMiOiJ0bHMifQ==','vmess://eyJ2IjoiMiIsInBzIjoi576O5Zu9LTQuMzlNQi9zKFlvdXR1YmU65LiN6Imv5p6XKSIsImFkZCI6IjE5OC4yLjE5Ni40OSIsInBvcnQiOiI1NDQzNCIsInR5cGUiOiJub25lIiwiaWQiOiI0MTgwNDhhZi1hMjkzLTRiOTktOWIwYy05OGNhMzU4MGRkMjQiLCJhaWQiOiI2NCIsIm5ldCI6InRjcCIsInBhdGgiOiIvIiwiaG9zdCI6IiIsInRscyI6IiJ9']

    # rawæ•°æ®å»é‡
    raw_list = copy.deepcopy(sorted(set(raw_list),key=raw_list.index))
    # base64åŠ å¯†
    encoder = base64.b64encode(('\n'.join(raw_list)).encode("utf-8"))
    # è§£ç ä¸º utf-8 å­—ç¬¦ä¸²
    try:
        # ç”Ÿæˆé€šç”¨è®¢é˜…
        open('dist/sub', 'w+',encoding='utf-8').write(encoder.decode('utf-8'))
    except Exception as e:
        logging.error(f'================================é€šç”¨è®¢é˜…ç”Ÿæˆå¤±è´¥!:{e}==========================================')

    # ç”Ÿæˆé€šç”¨è®¢é˜…äºŒç»´ç 
    try:
        img = qrcode.make('\n'.join(raw_list),version=None,
                    error_correction=constants.ERROR_CORRECT_M,
                    box_size=10, border=4,
                    image_factory=None,
                    mask_pattern=None)
        with open('dist/sub.jpg', 'wb') as qrc:
            img.save(qrc)
    except Exception as e:
        logging.error(f'================================äºŒç»´ç ç”Ÿæˆå¤±è´¥!:{e}==========================================')
    
    try:
        clash_dict = generate_clash_config(raw_list,{})
        with open('dist/clash.yml', 'w+',encoding='utf-8') as file:
            file.write(yaml.dump(clash_dict, allow_unicode=True,default_flow_style=False,sort_keys=False))
    except Exception as e:
        logging.error(f'================================clashæ–‡ä»¶ç”Ÿæˆå¤±è´¥!:{e}==========================================')

    logging.info(f'=========================================================================clashé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ!')
    logging.info(f'')
    logging.info(f'')
    logging.info(f'')
    logging.info(f'')
    logging.info(f'=========================================================================èŠ‚ç‚¹æ›´æ–°å®Œæˆ!')
