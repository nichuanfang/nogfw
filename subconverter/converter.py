# å¤„ç†generate.iniæ–‡ä»¶
import re
from urllib import request, parse
import requests,base64,json,urllib
from urllib import parse
import json
import base64
import logging

LOG_FORMAT = "%(asctime)s - %(levelname)s - %(message)s"
DATE_FORMAT = "%m/%d/%Y %H:%M:%S %p"
logging.basicConfig(level=logging.INFO, format=LOG_FORMAT, datefmt=DATE_FORMAT)

# quanxçš„æ­£åˆ™
quanx_pattern = r'{quanx}'
# clashçš„æ­£åˆ™
clash_pattern = r'{clash}'
# v2rayçš„æ­£åˆ™
v2ray_pattern = r'{v2ray}'

# åœ°åŒºåˆ†æ•° ç”¨äºèŠ‚ç‚¹æ’åº keyä¸ºå¸¸è§åœ°åŒºä»£å· valueä¸ºåˆ†æ•° 
# æ ¹æ®ç›´çº¿è·ç¦»æ‰“åˆ† ç›®æ ‡åœ°ç‚¹åˆ°ä¸­å›½ä¸Šæµ·çš„ç›´çº¿è·ç¦» 
area_scores = {
    # ä¸­å›½ 4000km
    'ğŸ‡¨ğŸ‡³': 1/4,
    # é¦™æ¸¯ 1227km
    'ğŸ‡­ğŸ‡°': 1/1.227,
    # æ–°åŠ å¡ 3797km
    'ğŸ‡¸ğŸ‡¬': 1/3.797,
    # å°æ¹¾ 684km
    'ğŸ‡¹ğŸ‡¼': 1/0.684,
    # æ—¥æœ¬ 1621km
    'ğŸ‡¯ğŸ‡µ': 1/1.621,
    # éŸ©å›½ 834
    'ğŸ‡°ğŸ‡·': 1/0.834,
    # ç¾å›½ 10373km
    'ğŸ‡ºğŸ‡¸': 1/10.373,
    # å°åº¦ 2984km
    'ğŸ‡®ğŸ‡³': 1/29.84,
    # è‹±å›½ 7779km
    'ğŸ‡¬ğŸ‡§': 1/77.79,
    # æ¾³å¤§åˆ©äºš 7474km
    'ğŸ‡¦ğŸ‡º': 1/74.74,
    # è‹±å±ç»´å°”äº¬ç¾¤å²› 7779km
    'ğŸ‡»ğŸ‡¬': 1/77.79,
    # è·å…° 7486km
    'ğŸ‡³ğŸ‡±': 1/74.86,
    # ä¹Œå…‹å…° 5947km
    'ğŸ‡ºğŸ‡¦': 1/59.47,
    # ä»¥è‰²åˆ— 6319km
    'ğŸ‡®ğŸ‡±': 1/63.19,
    # å°åº¦å°¼è¥¿äºš 5193km
    'ğŸ‡®ğŸ‡©': 1/51.93,
    # default 15000km
    'other': 1/15.0
}

def get_area_score(proxy):
    """è·å–èŠ‚ç‚¹åœ°åŒºåˆ†æ•°

    Args:
        proxy (_type_): èŠ‚ç‚¹åç§°

    Returns:
        _type_: å¾—åˆ†
    """    
    if re.search('(é¦™æ¸¯|Hong Kong|HK|hk)',proxy):
        return area_scores['ğŸ‡­ğŸ‡°']
    elif re.search('(æ—¥æœ¬|Japan|JP|jp)',proxy):
        return area_scores['ğŸ‡¯ğŸ‡µ']
    elif re.search('(éŸ©å›½|Korea|KR|kr)',proxy):
        return area_scores['ğŸ‡°ğŸ‡·']
    elif re.search('(æ–°åŠ å¡|Singapore|SG|sg)',proxy):
        return area_scores['ğŸ‡¸ğŸ‡¬']
    elif re.search('(å°æ¹¾|Taiwan|TW|tw|å°åŒ—)',proxy):
        return area_scores['ğŸ‡¹ğŸ‡¼']
    elif re.search('(ç¾å›½|United States|US|us)',proxy):
        return area_scores['ğŸ‡ºğŸ‡¸']
    elif re.search('(å°åº¦|India|IN|in)',proxy):
        return area_scores['ğŸ‡®ğŸ‡³']
    elif re.search('(è‹±å›½|England|GB|gb)',proxy):
        return area_scores['ğŸ‡¬ğŸ‡§']
    elif re.search('(æ¾³å¤§åˆ©äºš|Australia|AU|au)',proxy):
        return area_scores['ğŸ‡¦ğŸ‡º']
    elif re.search('(è‹±å±ç»´å°”äº¬ç¾¤å²›|VG|vg)',proxy):
        return area_scores['ğŸ‡»ğŸ‡¬']
    elif re.search('(è·å…°|Holland|NL|nl)',proxy):
        return area_scores['ğŸ‡³ğŸ‡±']
    elif re.search('(ä¹Œå…‹å…°|Ukraine|UA|ua)',proxy):
        return area_scores['ğŸ‡ºğŸ‡¦']
    elif re.search('(ä»¥è‰²åˆ—|Israel|IL|il)',proxy):
        return area_scores['ğŸ‡®ğŸ‡±']
    elif re.search('(å°åº¦å°¼è¥¿äºš|Indonesia|ID|id)',proxy):
        return area_scores['ğŸ‡®ğŸ‡©']
    elif re.search('(ä¸­è½¬èŠ‚ç‚¹)',proxy):
        return area_scores['ğŸ‡¨ğŸ‡³']
    else:
        return area_scores['other']

def decode_base64(data, decode_utf8=True):
    missing_padding = 4 - len(data) % 4
    if missing_padding:
        data += '='* missing_padding
    if decode_utf8:
        return base64.urlsafe_b64decode(data.encode('ascii')).decode("utf-8")
    else:
        return base64.urlsafe_b64decode(data.encode('ascii'))

def encode_base64(data):
    return base64.urlsafe_b64encode(data.encode("utf-8")).decode("utf-8")

def get_remarks(ssrConfig):
    param = parse.parse_qs(parse.urlsplit(ssrConfig).query)
    remarks_base64 =  param['remarks'][0].replace('-', '+').replace('_', '/')
    remarks = decode_base64(remarks_base64, False)
    return parse.quote(remarks)

def convert_ssr2ss(ssrConfig):
    ssConfig = "ss://"
    networkConfig = ssrConfig.split('/?')[0].split(':')
    serverIP = networkConfig[0]
    serverPort = networkConfig[1]
    encryption = networkConfig[3]
    passwd = decode_base64(networkConfig[5])
    remarks = get_remarks(ssrConfig)
    ssConfig += encode_base64(encryption + ":" + passwd) + "@" + serverIP + ":" + serverPort + "/#" + remarks
    return ssConfig

def proxy_speed(proxy:str):
    match = re.search(r'\d+.\d+',proxy.split('-')[-1])
    if match is not None:
        if proxy.split('-')[-1].lower().__contains__('kb'):
            return  float(match.group())/1000
        else:
            return  float(match.group())
    else:
        return 0.0

def sort_func(proxy):
    """èŠ‚ç‚¹å¾—åˆ†ç³»ç»Ÿ è¯„ä¼°èŠ‚ç‚¹è´¨é‡ ç»“åˆé«˜å¯ç”¨æ¨¡å¼ å®ç°èŠ‚ç‚¹ä¼˜é€‰

    Args:
        proxy (_type_): èŠ‚ç‚¹åç§°

    Returns:
        _type_: èŠ‚ç‚¹åç§°
    """    
    final_score = 0.0
    if proxy == 'none':
        return final_score
    # 1. æ ¹æ®æ ‡æ³¨å·²å­˜æ´»ä¸”å­˜æ´»å¤©æ•°æ¥åŠ åˆ† é»˜è®¤ä¸º1åˆ†(çœ‹ä½œå­˜æ´»ä¸€å¤©)
    alive_score = 1.0
    # example: [3] (å·²å­˜æ´»12å¤©)ä¸­è½¬èŠ‚ç‚¹-13.06MB/s
    alive_match = re.search(r'(å·²å­˜æ´»(\d*)å¤©)',proxy)
    if alive_match is not None:
        # æå–æ•°å­—
        alive_str = alive_match.group()
        alive_res = re.findall(r"\d+",alive_str)
        if len(alive_res) != 0 :
            alive_score = float(alive_res[0])
    # 2. åœ°åŒºåœ¨æŒ‡å®šä½å»¶è¿Ÿåœ°åŒºçš„ ä¼˜å…ˆçº§åŠ åˆ†
    area_score = get_area_score(proxy)
    # 3. æµ‹é€Ÿç»“æœè¶Šå¿«çš„ åŠ åˆ† å•ä½ MB/s
    speed_score = 1.0 if proxy_speed(proxy)==0.0 else proxy_speed(proxy)
    match = re.search(r'\d+.\d+',proxy.split('-')[-1])
    if match is not None:
        if proxy.split('-')[-1].lower().__contains__('kb'):
            speed_score =  float(match.group())/1000
        else:
            speed_score =  float(match.group())
    final_score = alive_score*area_score*speed_score
    logging.info(f'============================================================èŠ‚ç‚¹å¾—åˆ†ç»Ÿè®¡====================================================================')
    logging.info(f'')
    logging.info(f'')
    logging.info(f'------------------------------------------------------------èŠ‚ç‚¹:{proxy}æ€»å¾—åˆ†:{final_score}')
    logging.info(f'----------------------------------------------------------------èŠ‚ç‚¹:{proxy}å­˜æ´»å¤©æ•°å¾—åˆ†:{alive_score}')
    logging.info(f'----------------------------------------------------------------èŠ‚ç‚¹:{proxy}åœ°åŒºå¾—åˆ†:{area_score}')
    logging.info(f'----------------------------------------------------------------èŠ‚ç‚¹:{proxy}æµ‹é€Ÿç»“æœå¾—åˆ†:{speed_score}')
    logging.info(f'')
    logging.info(f'')
    return final_score

def get_tag(node:str):
    type = node.split('://')[0]
    # è·å–èŠ‚ç‚¹çš„åŸå§‹æ ‡ç­¾
    # ss
    if type == 'ss':
        logging.info(f'å¼€å§‹å¤„ç†ssèŠ‚ç‚¹:{node}')
        urlencoded_node = node.split('#')[1]
        # urlè§£ç 
        return parse.unquote(urlencoded_node)
    if type == 'ssr':
        logging.info(f'å¼€å§‹å¤„ç†ssrèŠ‚ç‚¹:{node}')
        b64encoded_node = node.split('//')[1]
        sconfig = decode_base64(b64encoded_node)
        # ssé“¾æ¥
        ss_node = convert_ssr2ss(sconfig)
        return (parse.unquote(ss_node.split('#')[1]),ss_node)
    # trojan
    elif type == 'trojan':
        logging.info(f'å¼€å§‹å¤„ç†trojanèŠ‚ç‚¹:{node}')
        urlencoded_node = node.split('#')[1]
        return parse.unquote(urlencoded_node)
    # vmess
    elif type == 'vmess':
        logging.info(f'å¼€å§‹å¤„ç†vmessèŠ‚ç‚¹:{node}')
        # å…ˆå¯¹vmessåè®®åé¢base64è§£ç  è½¬ä¸ºjson å…¶ä¸­çš„pså­—æ®µå³ä¸ºtag
        b64encoded_node = node.split('//')[1]
        b64decoded_node = base64.b64decode(b64encoded_node).decode('utf-8') # type: ignore
        json_node = json.loads(b64decoded_node)
        return json_node['ps']
    else:
        logging.info(f'æœªçŸ¥åè®®èŠ‚ç‚¹:{node}')
        return 'none'

def tag(node:str,new_tag):
    
    type = node.split('://')[0]
    # ç»™èŠ‚ç‚¹æ›¿æ¢æ–°çš„tag
     # ss
    if type == 'ss':
        logging.info(f'å¼€å§‹ç»™ssèŠ‚ç‚¹:{node}æ‰“tag')
        urlencoded_node = node.split('#')[1]
        # urlè§£ç 
        return node.split('#')[0]+'#'+ parse.quote(new_tag)
    if type == 'ssr':
        logging.info(f'å¼€å§‹ç»™ssrèŠ‚ç‚¹:{node}æ‰“tag')
        b64encoded_node = node.split('//')[1]
        sconfig = decode_base64(b64encoded_node)
        # ssé“¾æ¥
        urlencoded_node = convert_ssr2ss(sconfig).split('#')[1]
        return parse.unquote(urlencoded_node)
    # trojan
    elif type == 'trojan':
        logging.info(f'å¼€å§‹ç»™trojanèŠ‚ç‚¹:{node}æ‰“tag')
        urlencoded_node = node.split('#')[1]
        return node.split('#')[0]+'#'+ parse.quote(new_tag)
    # vmess
    elif type == 'vmess':
        logging.info(f'å¼€å§‹ç»™vmessèŠ‚ç‚¹:{node}æ‰“tag')
        # å…ˆå¯¹vmessåè®®åé¢base64è§£ç  è½¬ä¸ºjson å…¶ä¸­çš„pså­—æ®µå³ä¸ºtag
        b64encoded_node = node.split('//')[1]
        b64decoded_node = base64.b64decode(b64encoded_node).decode('utf-8')
        json_node = json.loads(b64decoded_node)
        json_node['ps'] = new_tag

        json_str = json.dumps(json_node,ensure_ascii=False)
        return 'vmess://'+ base64.b64encode(json_str.encode("utf-8")).decode('utf-8')
    else:
        return node

def handle_nodes(nodes:list[str]):
    # è·å–èŠ‚ç‚¹tagä¸è¯¥èŠ‚ç‚¹çš„å°å°„å­—å…¸

    # key: èŠ‚ç‚¹ä¸­æ–‡å value: èŠ‚ç‚¹åŸå§‹æ•°æ®
    tag_node_dict:dict[str,str] = {}

    for node in nodes:
        # å»é™¤sså’ŒssrèŠ‚ç‚¹
        if node.startswith('ss://') or node.startswith('ssr://'):
            continue
        get_tag_res = get_tag(node)
        if type(get_tag_res) == tuple:
            tag_node_dict[get_tag_res[0]] = get_tag_res[1] # type: ignore
        else:
            tag_node_dict[get_tag(node)] = node # type: ignore

    sorted_tag_node_keys = sorted(tag_node_dict,key=sort_func,reverse=True)
    new_nodes = []
    # èŠ‚ç‚¹é‡æ’åº
    for index,sorted_tag_node_key in enumerate(sorted_tag_node_keys):
        sorted_tag_node = tag_node_dict[sorted_tag_node_key]
        # è¿‡æ»¤é€Ÿåº¦ä½äº4.8Mbpsçš„èŠ‚ç‚¹(å³é€Ÿåº¦ä½äº600KB/Sçš„èŠ‚ç‚¹)
        speed = proxy_speed(sorted_tag_node_key)
        if speed*8 < 4.8:
            continue
        # å¤„ç†èŠ‚ç‚¹ å»é™¤ç‰¹æ®Šæ ‡è¯†(ä¾‹å¦‚: youtubeä¸è‰¯æ—) æ·»åŠ æ ‡ç­¾ [åºå·]
        new_nodes.append(tag(sorted_tag_node,f'[{index+1}] '+sorted_tag_node_key.replace('(Youtube:ä¸è‰¯æ—)','')))

    return new_nodes

with open('subconverter/generate_template.ini','r+',encoding='utf-8') as generate_template:
    generate_template_ini = generate_template.read()

def add_quanx(nodes:list[str],template:str = generate_template_ini):
    """æ·»åŠ qxèŠ‚ç‚¹

    Args:
        nodes (list[str]): èŠ‚ç‚¹
    """   
    url = '|'.join(handle_nodes(nodes))[:-1]
    generate_ini = re.sub(quanx_pattern,f'{url}',template)
    with open('subconverter/generate.ini','w+',encoding='utf-8') as f:
        f.write(generate_ini)
    return generate_ini
        

def add_clash(nodes:list[str],template:str = generate_template_ini):
    """æ·»åŠ clashèŠ‚ç‚¹

    Args:
        nodes (list[str]): èŠ‚ç‚¹
    """    
    url = '|'.join(handle_nodes(nodes))[:-1]
    generate_ini = re.sub(clash_pattern,f'{url}',template)
    with open('subconverter/generate.ini','w+',encoding='utf-8') as f:
        f.write(generate_ini)
    return generate_ini

def add_v2ray(nodes:list[str],template:str = generate_template_ini):
    """æ·»åŠ v2rayèŠ‚ç‚¹

    Args:
        nodes (list[str]): èŠ‚ç‚¹
    """    
    url = '|'.join(handle_nodes(nodes))[:-1]
    generate_ini = re.sub(v2ray_pattern,f'{url}',template)
    with open('subconverter/generate.ini','w+',encoding='utf-8') as f:
        f.write(generate_ini)
    return generate_ini
